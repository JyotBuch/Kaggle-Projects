{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947d905b",
   "metadata": {},
   "source": [
    "# Breast Cancer Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a41dcd",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "Source : https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "\n",
    "Dataset Description : Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/\n",
    "\n",
    "The number of instances present in the model are 569, with 32 attributes.\n",
    "\n",
    "\n",
    "\n",
    "## Attribute Information\n",
    "ID number\n",
    "Diagnosis (M = malignant, B = benign)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "    1) radius (mean of distances from center to points on the perimeter)\n",
    "\t2) texture (standard deviation of gray-scale values)\n",
    "\t3) perimeter\n",
    "\t4) area\n",
    "\t5) smoothness (local variation in radius lengths)\n",
    "\t6) compactness (perimeter^2 / area - 1.0)\n",
    "\t7) concavity (severity of concave portions of the contour)\n",
    "\t8) concave points (number of concave portions of the contour)\n",
    "\t9) symmetry \n",
    "\t10)fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "\n",
    "## Task\n",
    "Predict the type of breast cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9d2806",
   "metadata": {},
   "source": [
    "### EDA and Pre-Processing\n",
    "\n",
    "In this section of our notebook, we perform some exploratory data analysis on our dataframe to get a general idea of what our dataframe consists of and to manipulate it if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42390847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeae970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us get some basic insight on our columns\n",
    "#and understand their properties and datatypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f604baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1743ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b90242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will drop the column \"Unnamed: 32\", because it has 0 non-null values.\n",
    "#Also, we can see that no other attributes have any missing values\n",
    "\n",
    "\n",
    "df.drop(['Unnamed: 32'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will also need to convert our categorical coumns, into numerical by using\n",
    "#hot encoding on the dataset\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "for column in df.columns:\n",
    "  if df[column].dtype == np.int64 or df[column].dtype == np.float64:\n",
    "    continue\n",
    "  df[column] = LabelEncoder().fit_transform(df[column])\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3cf162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check the ratio of Benign to Malignant cancer\n",
    "\n",
    "\n",
    "plt.figure(figsize=(13,6))\n",
    "df.diagnosis.value_counts().plot.pie(autopct=\"%.1f%%\")\n",
    "plt.title(\"Diagnosis Ratio\", fontsize = 20)\n",
    "plt.legend(['Benign','Malignant'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12c661",
   "metadata": {},
   "source": [
    "From the above pie chart, we can see that 62.7% of our entries have Benign Type Cancer and 37.3% have Malignant Cancer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa044d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A heatmap is used to graphically represent the correlation between the attibutes in our dataset\n",
    "#We will plot a heatmap to check for the highly correlated columns\n",
    "\n",
    "plt.figure(figsize=(25,20))\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba29d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are many attributes with correalation under less than 0.5.\n",
    "#Let us do further analysis on these columns\n",
    "\n",
    "\n",
    "high_corr_data = df.corr()\n",
    "high_corr_columns = high_corr_data.index[abs(high_corr_data['diagnosis'])>=0.5]\n",
    "high_corr_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a heatmap of these high correlated values\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.heatmap(df[high_corr_columns].corr(), annot=True, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b10772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us check the difference between the means values of attributes of the two types of cancer by using the\n",
    "#distplot feature.\n",
    "\n",
    "mean_col = ['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n",
    "\n",
    "for col in mean_col:\n",
    "    sns.displot(df, x=col, hue=\"diagnosis\", kind=\"kde\", multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9786d62d",
   "metadata": {},
   "source": [
    "From our above plots, it that the radius mean,texture mean, perimeter mean, area mean, smoothness mean,\n",
    "compactness mean, concavity mean, concave points mean, symmetry mean and the fractal dimenion mean is \n",
    "significantly varying in the different types of tumors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde2365e",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060855ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "#Splitting dependent and independent columns\n",
    "x = df.drop(columns = 'diagnosis')\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedbc9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into training and test sets\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6567cf5",
   "metadata": {},
   "source": [
    "Now that we have sampled our data and performed our basic analysism we will move on to testing our dataset for best the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab34307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us first import the model from the sklearn module\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report , confusion_matrix , accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694dc812",
   "metadata": {},
   "source": [
    "#### Testing for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6530f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logistic = LogisticRegression()\n",
    "model_logistic.fit(x_train, y_train)\n",
    "print('Logistic regression accuracy: {:.4f}'.format(accuracy_score(y_test, model_logistic.predict(x_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b2b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionmatrix = confusion_matrix(y_test, model_logistic.predict(x_test))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "ax.matshow(confusionmatrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confusionmatrix.shape[0]):\n",
    "    for j in range(confusionmatrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=confusionmatrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d331bb",
   "metadata": {},
   "source": [
    "#### Testing for Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74aa19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_randomforest = RandomForestClassifier()\n",
    "model_randomforest.fit(x_train, y_train)\n",
    "print('Random Forest accuracy: {:.4f}'.format(accuracy_score(y_test, model_randomforest.predict(x_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1853ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionmatrix = confusion_matrix(y_test, model_randomforest.predict(x_test))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "ax.matshow(confusionmatrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confusionmatrix.shape[0]):\n",
    "    for j in range(confusionmatrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=confusionmatrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d1b6ad",
   "metadata": {},
   "source": [
    "#### Testing for K Neighbours Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knnclassfier = KNeighborsClassifier()\n",
    "model_knnclassfier.fit(x_train, y_train)\n",
    "print('Random Forest accuracy: {:.4f}'.format(accuracy_score(y_test, model_knnclassfier.predict(x_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f189fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionmatrix = confusion_matrix(y_test, model_knnclassfier.predict(x_test))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "ax.matshow(confusionmatrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confusionmatrix.shape[0]):\n",
    "    for j in range(confusionmatrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=confusionmatrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0de642",
   "metadata": {},
   "source": [
    "#### Testing for XGBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ca31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBClassifier()\n",
    "model_xgb.fit(x_train, y_train)\n",
    "print('XGBoostClassifier accuracy: {:.4f}'.format(accuracy_score(y_test, model_xgb.predict(x_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionmatrix = confusion_matrix(y_test, model_xgb.predict(x_test))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "ax.matshow(confusionmatrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confusionmatrix.shape[0]):\n",
    "    for j in range(confusionmatrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=confusionmatrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a656438",
   "metadata": {},
   "source": [
    "#### Testing for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc4386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = SVC()\n",
    "model_svm.fit(x_train, y_train)\n",
    "print('SVM accuracy: {:.4f}'.format(accuracy_score(y_test, model_svm.predict(x_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f48ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionmatrix = confusion_matrix(y_test, model_svm.predict(x_test))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "ax.matshow(confusionmatrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confusionmatrix.shape[0]):\n",
    "    for j in range(confusionmatrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=confusionmatrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c8135",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection_dict = {\"Logistic Regression\" : accuracy_score(y_test, model_logistic.predict(x_test)),\n",
    "                           \"Random Forest Classifier\" : accuracy_score(y_test, model_randomforest.predict(x_test)),\n",
    "                               \"XGBoost Classifier\" :accuracy_score(y_test, model_xgb.predict(x_test)),\n",
    "                                    \"KNN Classifier\":accuracy_score(y_test, model_knnclassfier.predict(x_test)),\n",
    "                                        \"SVM\": accuracy_score(y_test, model_svm.predict(x_test))\n",
    "                       }\n",
    "\n",
    "pd.DataFrame(model_selection_dict.items(), columns=['Model','Accuracy Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2567be0",
   "metadata": {},
   "source": [
    "In our model seletion analysis we can see that the XGBoostClassifier Model has the maximum score of 98.25% accuracy. Let us furhter analyse this model before confirming our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac1dd21",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e1e3e0",
   "metadata": {},
   "source": [
    "Let us analyse our XGBoost model, by checking its precision, recall value and f1 score. test We do this by printing a classification report between the y_test values which we had separated from the dataset containing the actual answer to the test set variables, and the model predictions of the x_test set which was untrained and the class variable was unknown to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, model_xgb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b934ee05",
   "metadata": {},
   "source": [
    "A 0.99 precision is not bad! But there is still some scope of improvement. We might be able to get a slightly\n",
    "better result if we had tuned our model. We will do that ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be59e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedvalues= pd.DataFrame({'Actual': y_test, 'Predicted': model_xgb.predict(x_test)})\n",
    "predictedvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5017b0",
   "metadata": {},
   "source": [
    "Since we have trained our model with 98.25% accuracy, we might not need hyper parameter tuning but let us check it out just in case it helps our case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56e1302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "gsearch1.fit(x,y)\n",
    "\n",
    "\n",
    "print(\"Tuned XGBoost Parameters: {}\".format(gsearch1.best_params_))\n",
    "print(\"Best score is {}\".format(gsearch1.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ce09f",
   "metadata": {},
   "source": [
    "After tuning our hyper parameters, we can see our accuracy has gone up to 99.45%, which is roughly 1%\n",
    "higher than our previous prediction score. To analyse our tuned model further we will plot the confusion matrix and print a classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107f0078",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionmatrix = confusion_matrix(y_test, gsearch1.predict(x_test))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "ax.matshow(confusionmatrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confusionmatrix.shape[0]):\n",
    "    for j in range(confusionmatrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=confusionmatrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25921ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, gsearch1.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfba7663",
   "metadata": {},
   "source": [
    "A 100% precision. So now our model is well trained with the dataset in hand. It might produce some errors in\n",
    "real world datasets, but this was just a beginner project and everything built can always be improved further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tuned_values= pd.DataFrame({'Actual': y_test, 'Predicted': model_xgb.predict(x_test)})\n",
    "predicted_tuned_values.to_csv(\"final_predictions_with_tuning.csv\", index=False)\n",
    "predicted_tuned_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
